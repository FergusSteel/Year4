- "using audio features showed better performance for predicting musical genres compared to using users’ listening data ... the latter performed better on music recommendation [2](https://ar5iv.labs.arxiv.org/html/2104.00437#bib.bib2) and mood prediction"

>[!quote] "Deep learning allows learning representations mapping from different input data to an embedding space that can be used for multiple downstream tasks [6](https://ar5iv.labs.arxiv.org/html/2104.00437#bib.bib6). The most common approach for representation learning in the music domain is to train a audio-based classifier to predict some music aspects such as genre, mood, or instrument and then use the pre-trained model to extract embeddings that could be used in different tasks."
- **this paper isnt particuarly relevant but is interesting for learning more about latent space representations from embeddings**